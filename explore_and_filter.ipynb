{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('data//inaturalist_boletus_edulis_with_corine_climate_nonan.csv')\n",
    "df2 = pd.read_csv('data//inaturalist_boletus_edulis_with_coords_topography.csv')\n",
    "\n",
    "# Merge the columns from df2 into df based on the 'location' column\n",
    "df = df.merge(df2[['location', 'dem', 'slope', 'aspect', 'geomorphon']], on='location', how='left', suffixes=('', '_df2'))\n",
    "df = df.dropna()\n",
    "df = df[df['dem'] != -32768]\n",
    "\n",
    "df\n",
    "\n",
    "df.to_csv('data/inaturalist_boletus_edulis_with_corine_climate_topography.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mean_rain = df[rain_columns].mean()\n",
    "std_rain = df[rain_columns].std()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(mean_rain.index, mean_rain.values, color=\"blue\", linewidth=3, label=\"Mean Rainfall\")\n",
    "plt.fill_between(mean_rain.index, \n",
    "                 mean_rain - std_rain, \n",
    "                 mean_rain + std_rain, \n",
    "                 color=\"blue\", alpha=0.2, label=\"Â±1 Std Dev\")\n",
    "\n",
    "plt.xticks(range(len(rain_columns)), labels=[str(i) for i in range(len(rain_columns))])\n",
    "plt.xlabel(\"Days Ago (0 = today)\")\n",
    "plt.ylabel(\"Rainfall (mm)\")\n",
    "plt.title(\"Average Rainfall Trend with Variability\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_columns = [f'P_{i}' for i in range(1, 15) if f'P_{i}' in df.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define rain columns\n",
    "rain_columns = [f'P_{i}' for i in range(1, 15) if f'P_{i}' in df.columns]\n",
    "\n",
    "# Reshape dataframe into long format\n",
    "df_long = df[rain_columns].melt(var_name=\"Day\", value_name=\"Rain\")\n",
    "df_long[\"Day\"] = df_long[\"Day\"].str.extract(\"(\\d+)\").astype(int) - 1  # P1->0, P2->1...\n",
    "\n",
    "# Plot with seaborn\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.lineplot(\n",
    "    data=df_long, x=\"Day\", y=\"Rain\",\n",
    "    ci=95, n_boot=1000,  # bootstrap CI handled automatically\n",
    "    color=\"navy\"\n",
    ")\n",
    "plt.xlabel(\"Days Ago (0 = today)\")\n",
    "plt.ylabel(\"Rainfall (mm)\")\n",
    "plt.title(\"Rainfall Trends with 95% Bootstrapped CIs\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10,2))\n",
    "sns.heatmap([df[rain_columns].mean().values], \n",
    "            cmap=\"Blues\", annot=True, cbar=False,\n",
    "            xticklabels=[str(i) for i in range(len(rain_columns))])\n",
    "plt.xlabel(\"Days Ago (0 = today)\")\n",
    "plt.title(\"Average Rainfall Across Days Before Observation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = np.vstack([\n",
    "    df[rain_columns].mean().values,\n",
    "    df[rain_columns].std().values\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(10,2.5))\n",
    "sns.heatmap(stats, cmap=\"Blues\", annot=True, fmt=\".1f\", cbar=True,\n",
    "            xticklabels=[str(i) for i in range(len(rain_columns))],\n",
    "            yticklabels=[\"Mean\", \"Std Dev\"])\n",
    "plt.xlabel(\"Days Ago (0 = today)\")\n",
    "plt.title(\"Rainfall Statistics Across Days\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import ggplot, aes, geom_line, geom_ribbon, labs, theme_minimal, theme_xkcd\n",
    "import random\n",
    "\n",
    "# 1. Select rain columns from your dataframe\n",
    "rain_columns = [f'P_{i}' for i in range(1, 15) if f'P_{i}' in df.columns]\n",
    "\n",
    "# 2. Compute mean values\n",
    "mean_vals = df[rain_columns].mean().values\n",
    "\n",
    "# 3. Bootstrap for confidence intervals\n",
    "boot_means = []\n",
    "for _ in range(1000):\n",
    "    sample = df[rain_columns].sample(frac=1, replace=True).mean()\n",
    "    boot_means.append(sample.values)\n",
    "boot_means = np.array(boot_means)\n",
    "\n",
    "ci_lower = np.percentile(boot_means, 2.5, axis=0)\n",
    "ci_upper = np.percentile(boot_means, 97.5, axis=0)\n",
    "\n",
    "# 4. Create dataframe for plotting\n",
    "ci_df = pd.DataFrame({\n",
    "    \"Day\": range(len(rain_columns)),   # 0 = today, 13 = 13 days ago\n",
    "    \"Mean\": mean_vals,\n",
    "    \"Lower\": ci_lower,\n",
    "    \"Upper\": ci_upper\n",
    "})\n",
    "\n",
    "# 5. Plot with plotnine (ggplot2 style)\n",
    "p = (\n",
    "    ggplot(ci_df, aes(x=\"Day\", y=\"Mean\"))\n",
    "    + geom_line(color=\"navy\")\n",
    "    + geom_ribbon(aes(ymin=\"Lower\", ymax=\"Upper\"), alpha=0.2, fill=\"skyblue\")\n",
    "    + labs(\n",
    "        title=\"Rainfall Trends with 95% Bootstrapped CIs\",\n",
    "        x=\"Days Ago (0 = today)\",\n",
    "        y=\"Rainfall (mm)\"\n",
    "    )\n",
    "    + theme_xkcd()   # <-- White background\n",
    ")\n",
    "\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append variables for inference (on vector file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('data/negative_samples_within_land_10k.csv')\n",
    "\n",
    "# Function to extract coordinates from the location string\n",
    "def parse_coordinates(location_str):\n",
    "    # Check if the value is NaN or not a string\n",
    "    if pd.isna(location_str) or not isinstance(location_str, str):\n",
    "        return None, None\n",
    "    \n",
    "    # Use regex to extract numbers from the string format \"(lat, lon)\"\n",
    "    match = re.search(r'\\(([^,]+),\\s*([^)]+)\\)', location_str)\n",
    "    if match:\n",
    "        try:\n",
    "            lat = float(match.group(1).strip())\n",
    "            lon = float(match.group(2).strip())\n",
    "            return lat, lon\n",
    "        except ValueError:\n",
    "            return None, None\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Extract coordinates into separate columns\n",
    "df[['y', 'x']] = df['location'].apply(lambda x: pd.Series(parse_coordinates(x)))\n",
    "\n",
    "# Optional: Remove the original location column if you don't need it\n",
    "# df = df.drop('location', axis=1)\n",
    "\n",
    "# Save the new CSV with coordinate columns\n",
    "df.to_csv('data/negative_samples_within_land_10k_with_coords.csv', index=False)\n",
    "\n",
    "print(\"CSV file saved with separate x and y coordinate columns!\")\n",
    "print(f\"Total rows processed: {len(df)}\")\n",
    "print(f\"Rows with valid coordinates: {df[['x', 'y']].dropna().shape[0]}\")\n",
    "print(f\"Rows with missing coordinates: {df[['x', 'y']].isna().any(axis=1).sum()}\")\n",
    "print(\"\\nFirst few rows with new columns:\")\n",
    "print(df[['species', 'x', 'y', 'observed_on']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('negative_samples_within_polygons_updated.csv')\n",
    "\n",
    "df[\"species\"] = \"None\"\n",
    "# Remove rows containing NaN values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# If you want to reset the index after dropping rows\n",
    "df_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the cleaned DataFrame\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "# Load the GeoJSON file containing the polygon of Spain\n",
    "spain_polygon = gpd.read_file('spain.geojson')\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = df_cleaned\n",
    "\n",
    "# Extract latitude and longitude from the \"location\" column\n",
    "df[['latitude', 'longitude']] = df['location'].str.extract(r'\\(([^,]+),([^)]+)\\)').astype(float)\n",
    "\n",
    "# Drop the original \"location\" column\n",
    "df.drop(columns=['location'], inplace=True)\n",
    "\n",
    "# Convert the DataFrame to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude))\n",
    "\n",
    "# Ensure that both GeoDataFrames have the same CRS (Coordinate Reference System)\n",
    "gdf.crs = spain_polygon.crs\n",
    "\n",
    "# Perform a spatial join to keep only the points inside the polygon\n",
    "points_inside_polygon = gpd.sjoin(gdf, spain_polygon, op='within')\n",
    "\n",
    "# Drop unnecessary columns added during the join\n",
    "points_inside_polygon.drop(columns=['index_right'], inplace=True)\n",
    "points_inside_polygon\n",
    "# Save the filtered points to a new CSV file\n",
    "#points_inside_polygon.to_csv('points_inside_spain.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the variables to plot\n",
    "variables_to_plot = ['P', 'Tmin', 'Temp', 'RelHum', 'SpecHum', 'Pres', 'Tmax']\n",
    "\n",
    "# Aggregate the data across the 14 columns for each variable\n",
    "aggregated_data = {}\n",
    "for var in variables_to_plot:\n",
    "    aggregated_data[var] = points_inside_polygon[[f'{var}_{i}' for i in range(1, 15)]].mean(axis=1)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(len(variables_to_plot), 1, figsize=(10, 6 * len(variables_to_plot)))\n",
    "for i, var in enumerate(variables_to_plot):\n",
    "    ax = axs[i]\n",
    "    ax.hist(aggregated_data[var], bins=20, alpha=0.7, color='blue')\n",
    "    ax.set_title(f'Distribution of {var} across all days')\n",
    "    ax.set_xlabel(var)\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_inside_polygon.to_csv('boletus_spain_negative.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gchm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
